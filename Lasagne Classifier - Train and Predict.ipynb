{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.cross_validation\n",
    "\n",
    "import skimage.exposure\n",
    "import skimage.transform\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read training set info and make train/val split\n",
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "\n",
    "N_CLASSES = len(df.whaleID.unique())\n",
    "CLASS_IX = {ID: i for i, ID in enumerate(df.whaleID.unique())}\n",
    "\n",
    "#train_ix, val_ix = sklearn.cross_validation.train_test_split(range(len(df)))\n",
    "train_ix = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to load and preprocess image with random distortions\n",
    "\n",
    "# expects input images cropped to face region, 384x384\n",
    "DATA_DIR = './data/traincrop384'\n",
    "\n",
    "def prep_image(fn, seed=None):\n",
    "    if seed is None:\n",
    "        seed = np.random.randint(4294967295)\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    im = plt.imread('{}/{}'.format(DATA_DIR, fn))\n",
    "\n",
    "    # random adjustment of gamma\n",
    "    im = skimage.exposure.adjust_gamma(im, rng.uniform(0.5, 1.5))\n",
    "\n",
    "    # random crop of each border\n",
    "    x1, x2, y1, y2 = rng.randint(1, 48, 4)\n",
    "    im = im[y1:-y2, x1:-x2]\n",
    "    \n",
    "    # scale cropped region to square 320x320\n",
    "    im = skimage.transform.resize(im, (320, 320))\n",
    "    \n",
    "    im = im - 0.5\n",
    "\n",
    "    # convert axes to bc01\n",
    "    im = np.transpose(im, (2, 0, 1))[np.newaxis]\n",
    "\n",
    "    return lasagne.utils.floatX(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate a minibatch of augmented images and labels\n",
    "\n",
    "def batch(ix, batch_size, seed=None):\n",
    "    if seed is None:\n",
    "        seed = np.random.randint(4294967295)\n",
    "    rng = np.random.RandomState(seed)\n",
    "    seeds = rng.randint(0, 4294967295, batch_size)\n",
    "    \n",
    "    image_ix = rng.choice(ix, batch_size)\n",
    "    fns = (df.ix[i].Image for i in image_ix)\n",
    "    images = [prep_image(fn, seed) for fn, seed in zip(fns, seeds)]\n",
    "    images = np.concatenate(images)\n",
    "    \n",
    "    labels = np.array([CLASS_IX[df.whaleID[i]] for i in image_ix]).astype('int32')\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Context manager to generate batches in the background via a process pool\n",
    "\n",
    "import uuid, os, pickle, hashlib\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "class BatchGenCM:\n",
    "    def __init__(self, batch_fn, ix, batch_size, seed=None, num_workers=8):\n",
    "        self.batch_fn = batch_fn\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.ix = ix\n",
    "        if seed is None:\n",
    "            seed = np.random.randint(4294967295)\n",
    "        self.seed = str(seed)\n",
    "        self.id = uuid.uuid4()\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.jobq = Queue(maxsize=self.num_workers)\n",
    "        self.doneq = Queue()\n",
    "        self.processes = []\n",
    "        self.current_batch = 0\n",
    "        self.finished_batches = []\n",
    "        \n",
    "        def f(batch_fn, ix, batch_size):\n",
    "            while True:\n",
    "                n = self.jobq.get()\n",
    "                if n is None:\n",
    "                    break\n",
    "                seed = int(hashlib.md5(self.seed + str(n)).hexdigest(), 16) % 4294967295\n",
    "                batch = batch_fn(ix, batch_size, seed)\n",
    "                pickle.dump(batch, open('/run/shm/{}-{}'.format(self.id, n), 'w'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                self.doneq.put(n)\n",
    "        \n",
    "        for i in range(self.num_workers):\n",
    "            self.jobq.put(i)\n",
    "\n",
    "            p = Process(target=f, args=(self.batch_fn, self.ix, self.batch_size))\n",
    "            self.processes.append(p)\n",
    "            p.start()        \n",
    "\n",
    "        return self\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def next(self):\n",
    "        n = self.current_batch\n",
    "        while n not in self.finished_batches:\n",
    "            i = self.doneq.get()\n",
    "            self.finished_batches.append(i)\n",
    "        \n",
    "        fn = '/run/shm/{}-{}'.format(self.id, n)\n",
    "        batch = pickle.load(open(fn))\n",
    "        os.system('rm {}'.format(fn))\n",
    "\n",
    "        self.jobq.put(n + self.num_workers)        \n",
    "        self.current_batch += 1\n",
    "        return batch\n",
    "            \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        for _ in range(self.num_workers):\n",
    "            self.jobq.put(None)\n",
    "        for process in self.processes:\n",
    "            process.join()\n",
    "        while not self.doneq.empty():\n",
    "            _ = next(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Neon's dropout works a bit differently than Lasagne, matching it just in case it matters\n",
    "\n",
    "from lasagne.layers import Layer\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from lasagne.random import get_rng\n",
    "\n",
    "class NeonDropoutLayer(Layer):\n",
    "    def __init__(self, incoming, p=0.5, **kwargs):\n",
    "        super(NeonDropoutLayer, self).__init__(incoming, **kwargs)\n",
    "        self._srng = RandomStreams(get_rng().randint(1, 2147462579))\n",
    "        self.p = p\n",
    "\n",
    "    def get_output_for(self, input, deterministic=False, **kwargs):\n",
    "        if deterministic:\n",
    "            return (1 - self.p) * input\n",
    "        else:\n",
    "            retain_prob = 1 - self.p\n",
    "\n",
    "            # use nonsymbolic shape for dropout mask if possible\n",
    "            input_shape = self.input_shape\n",
    "            if any(s is None for s in input_shape):\n",
    "                input_shape = input.shape\n",
    "\n",
    "            return input * self._srng.binomial(input_shape, p=retain_prob,\n",
    "                                               dtype=theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "#from lasagne.layers.dnn import Conv2DDNNLayer as Conv\n",
    "#from lasagne.layers.dnn import Pool2DDNNLayer as Pool\n",
    "from lasagne.layers.corrmm import Conv2DMMLayer as Conv\n",
    "from lasagne.layers import Pool2DLayer as Pool\n",
    "\n",
    "from lasagne.layers import batch_norm\n",
    "\n",
    "from lasagne.nonlinearities import softmax, rectify\n",
    "from lasagne.init import GlorotUniform\n",
    "from lasagne.utils import floatX\n",
    "\n",
    "def build_model(batch_size, input_width, input_height):\n",
    "    net = {}\n",
    "    activation = lasagne.nonlinearities.rectify\n",
    "\n",
    "    nfilt = 32\n",
    "\n",
    "    l = InputLayer((batch_size, 3, input_width, input_height))\n",
    "    net['input'] = l\n",
    "    l = batch_norm(Conv(l, nfilt, 2, stride=2, nonlinearity=rectify, W=GlorotUniform(gain='relu')))\n",
    "\n",
    "    for _ in range(5):\n",
    "        if nfilt >= 1024:\n",
    "            nfilt = 1024\n",
    "        l = batch_norm(Conv(l, nfilt, 3, stride=1, pad=0, nonlinearity=rectify, W=GlorotUniform(gain='relu')))\n",
    "        l = Pool(l, 2, stride=2)\n",
    "        nfilt *= 2\n",
    "    l = batch_norm(Conv(l, nfilt, 3,stride=1, pad=0, nonlinearity=rectify, W=GlorotUniform(gain='relu')))\n",
    "        \n",
    "    l = NeonDropoutLayer(l, p=0.8)\n",
    "    l = DenseLayer(l, num_units=447, nonlinearity=softmax, W=GlorotUniform(gain='relu'))\n",
    "    net['output'] = l\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = build_model(32, 320, 320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.tensor4()\n",
    "y = T.ivector()\n",
    "\n",
    "prob = lasagne.layers.get_output(net['output'], X)\n",
    "loss = T.mean(lasagne.objectives.categorical_crossentropy(prob, y))\n",
    "acc = T.mean(lasagne.objectives.categorical_accuracy(prob, y))\n",
    "\n",
    "test_prob = lasagne.layers.get_output(net['output'], X, deterministic=True)\n",
    "test_loss = T.mean(lasagne.objectives.categorical_crossentropy(test_prob, y))\n",
    "test_acc = T.mean(lasagne.objectives.categorical_accuracy(test_prob, y))\n",
    "\n",
    "params = lasagne.layers.get_all_params(net['output'], trainable=True)\n",
    "\n",
    "updates = lasagne.updates.adadelta(loss, params, learning_rate=1.0, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_prob = theano.function([X], test_prob)\n",
    "f_train = theano.function([X, y], [loss, acc], updates=updates)\n",
    "f_val = theano.function([X, y], [test_loss, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# After 300 epochs, should be around 1.9-2.0 val loss\n",
    "BATCH_SIZE = 32\n",
    "N_BATCH = len(train_ix) / BATCH_SIZE\n",
    "N_VAL_BATCH = 10\n",
    "\n",
    "lasagne.random.set_rng(np.random.RandomState(SEED))\n",
    "with BatchGenCM(batch, train_ix, 32, seed=SEED) as train_bg:\n",
    "    for epoch in range(300):\n",
    "        loss_train = 0\n",
    "        for _ in range(N_BATCH):\n",
    "            loss_batch, _ = f_train(*next(train_bg))\n",
    "            loss_train += loss_batch\n",
    "        print('epoch {:03} - tr: {:.04f}'.format(epoch, loss_train/N_BATCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pvs = lasagne.layers.get_all_param_values(net['output'])\n",
    "pickle.dump(pvs, open('./cls_seed{}_300_epochs.pkl'.format(SEED),'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = build_model(None, 320, 320)\n",
    "lasagne.layers.set_all_param_values(net['output'], pvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Make Predictions on Test Image Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './data/testcrops_filteredB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_test_image(fn, seed):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    im = plt.imread('{}/{}'.format(DATA_DIR, fn))\n",
    "    im = im/255.\n",
    "    if min(im.shape[:2]) < 384:\n",
    "        im = skimage.transform.resize(im, (384, 384))\n",
    "    im = skimage.exposure.adjust_gamma(im, rng.uniform(0.5, 1.5))\n",
    "    x1, x2, y1, y2 = rng.randint(1, 48, 4)\n",
    "    im = im[y1:-y2, x1:-x2]\n",
    "    im = skimage.transform.resize(im, (320, 320))\n",
    "    \n",
    "    im = im - 0.5\n",
    "\n",
    "    # Shuffle axes to c01\n",
    "    im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "\n",
    "    return lasagne.utils.floatX(im[np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "rng = np.random.RandomState(SEED)\n",
    "\n",
    "p = []\n",
    "for i in range(len(df)):\n",
    "    seeds = np.random.randint(0, 4294967295, 64)\n",
    "    im = np.concatenate(joblib.Parallel(n_jobs=8)(joblib.delayed(prep_test_image)(df.Image[i], s) for s in seeds))\n",
    "    p.append(f_prob(im).mean(0))\n",
    "p = np.array(p)\n",
    "\n",
    "ix_map = np.array([CLASS_IX[i] for i in df.columns[1:]])\n",
    "df.ix[:, 1:] = p[:, ix_map]\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
